{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"Sentiment_analysis_using_lime_and_lstm(Only_code) (1).ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"z-p8wFdWn-hl"},"source":["#Sentiment Analysis of IMDB Movie Reviews"]},{"cell_type":"code","metadata":{"id":"O1F2ltqnquxM"},"source":["!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zu8Py4Ruq5h0"},"source":["# the reviews train data\n","downloaded = drive.CreateFile({'id': '1JFXUq7riGEHXpn7B5G64wt8NNNUMboHq'})\n","downloaded.GetContentFile('IMDB Dataset.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-07-08T05:37:39.436497Z","iopub.status.idle":"2021-07-08T05:37:39.436973Z"},"trusted":true,"id":"E4ANTU7vn-ho"},"source":["#Load the libraries\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import nltk\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import LabelBinarizer\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from wordcloud import WordCloud,STOPWORDS\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize,sent_tokenize\n","from bs4 import BeautifulSoup\n","import spacy\n","import re,string,unicodedata\n","from nltk.tokenize.toktok import ToktokTokenizer\n","from nltk.stem import LancasterStemmer,WordNetLemmatizer\n","from sklearn.linear_model import LogisticRegression,SGDClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from textblob import TextBlob\n","from textblob import Word\n","from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n","\n","# import os\n","# print(os.listdir(\"../input\"))\n","# import warnings\n","# warnings.filterwarnings('ignore')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"be1b642cce343f7a8f68f8c91f7c50372cdf4381","id":"FhlFZMDqn-hp"},"source":["**Import the training dataset**"]},{"cell_type":"code","metadata":{"_uuid":"4c593c17588723c0b0b0f19851cb70a8447ced76","scrolled":true,"execution":{"iopub.status.busy":"2021-07-08T05:37:39.439055Z","iopub.status.idle":"2021-07-08T05:37:39.439482Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":361},"id":"tZvPB2dYn-hq","outputId":"3d5ccfaa-d322-4993-dc77-7b077cfc845e"},"source":["#importing the training data\n","imdb_data=pd.read_csv('IMDB Dataset.csv')\n","print(imdb_data.shape)\n","imdb_data.head(10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(50000, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Probably my all-time favorite movie, a story o...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I sure would like to see a resurrection of a u...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>This show was an amazing, fresh &amp; innovative i...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Encouraged by the positive comments about this...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>If you like original gut wrenching laughter yo...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","5  Probably my all-time favorite movie, a story o...  positive\n","6  I sure would like to see a resurrection of a u...  positive\n","7  This show was an amazing, fresh & innovative i...  negative\n","8  Encouraged by the positive comments about this...  negative\n","9  If you like original gut wrenching laughter yo...  positive"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"_uuid":"1ad3773974351ed9bdf389b2847d7475b36c2295","id":"3VTSdz5pn-hq"},"source":["**Exploratery data analysis**"]},{"cell_type":"code","metadata":{"_uuid":"7f11c83b1320c8982b36889145f7f770563674a8","execution":{"iopub.status.busy":"2021-07-08T05:37:39.440639Z","iopub.status.idle":"2021-07-08T05:37:39.441093Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"gMlfsatOn-hr","outputId":"6291c5b3-60cc-4221-d140-3be7fe4cc86d"},"source":["#Summary of the dataset\n","imdb_data.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>50000</td>\n","      <td>50000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>49582</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Loved today's show!!! It was a variety and not...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>5</td>\n","      <td>25000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   review sentiment\n","count                                               50000     50000\n","unique                                              49582         2\n","top     Loved today's show!!! It was a variety and not...  positive\n","freq                                                    5     25000"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"_uuid":"453c3fd238f62ab8f649eb01771817e25bc0c77d","id":"xvG7Tatjn-hr"},"source":["**Sentiment count**"]},{"cell_type":"code","metadata":{"_uuid":"cb6bb97b0f851947dcf341a1de5708a1f2bc64c1","execution":{"iopub.status.busy":"2021-07-08T05:37:39.442479Z","iopub.status.idle":"2021-07-08T05:37:39.442973Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"hTDIAAeyn-hs","outputId":"7910cae9-a451-4c0f-8d11-5e03e9db1eb7"},"source":["#sentiment count\n","imdb_data['sentiment'].value_counts()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["positive    25000\n","negative    25000\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"-Ez1Jar3n-hs"},"source":["We can see that the dataset is balanced."]},{"cell_type":"markdown","metadata":{"_uuid":"f61964573faababe1f7897b77d32815a24954d2f","id":"QP0S2fnZn-hs"},"source":["**Spliting the training dataset**"]},{"cell_type":"code","metadata":{"_uuid":"d3aaabff555e07feb11c72cc3a6e457615975ffe","execution":{"iopub.status.busy":"2021-07-08T05:37:39.444352Z","iopub.status.idle":"2021-07-08T05:37:39.444810Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"4sHFp6Q_n-ht","outputId":"4f28b542-a782-4ee3-e24a-830b2ac846cd"},"source":["#split the dataset  \n","#train dataset\n","train_reviews=imdb_data.review[:40000]\n","train_sentiments=imdb_data.sentiment[:40000]\n","#test dataset\n","test_reviews=imdb_data.review[40000:]\n","test_sentiments=imdb_data.sentiment[40000:]\n","print(train_reviews.shape,train_sentiments.shape)\n","print(test_reviews.shape,test_sentiments.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(40000,) (40000,)\n","(10000,) (10000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"90da29c3b79f46f41d7391a2a116065b616d0fac","id":"DzaIptkin-ht"},"source":["**Text normalization**"]},{"cell_type":"code","metadata":{"_uuid":"f000c43d91f68f6668539f089c6a54c5ce3bd819","execution":{"iopub.status.busy":"2021-07-08T05:37:39.446227Z","iopub.status.idle":"2021-07-08T05:37:39.446761Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"Bb1fo-Y-n-hu","outputId":"417e94c8-4a01-4c00-9ce1-369dbdb79037"},"source":["import nltk\n","nltk.download('stopwords')\n","#Tokenization of text\n","tokenizer=ToktokTokenizer()\n","#Setting English stopwords\n","stopword_list=nltk.corpus.stopwords.words('english')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"328b6e5977da3e055ad4b2e11a31e5e12ccf3b16","id":"pODKOMGxn-hu"},"source":["**Removing html strips and noise text**"]},{"cell_type":"code","metadata":{"_uuid":"6f6fcafbdadcdcb0c164e37d71fb9d1623f74d0a","execution":{"iopub.status.busy":"2021-07-08T05:37:39.448214Z","iopub.status.idle":"2021-07-08T05:37:39.448783Z"},"trusted":true,"id":"Wj5rLeX_n-hu"},"source":["#Removing the html strips\n","def strip_html(text):\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    return soup.get_text()\n","\n","#Removing the square brackets\n","def remove_between_square_brackets(text):\n","    return re.sub('\\[[^]]*\\]', '', text)\n","\n","#Removing the noisy text\n","def denoise_text(text):\n","    text = strip_html(text)\n","    text = remove_between_square_brackets(text)\n","    return text\n","#Apply function on review column\n","imdb_data['review']=imdb_data['review'].apply(denoise_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"88117b74761d1047924d6d70f76642faa0e706ac","id":"2zKeg5Jdn-hv"},"source":["**Removing special characters**"]},{"cell_type":"code","metadata":{"_uuid":"219da72b025121fd98081df50ae0fcaace10cc9d","execution":{"iopub.status.busy":"2021-07-08T05:37:39.450109Z","iopub.status.idle":"2021-07-08T05:37:39.450709Z"},"trusted":true,"id":"-wzxZvSzn-hv"},"source":["#Define function for removing special characters\n","def remove_special_characters(text, remove_digits=True):\n","    pattern=r'[^a-zA-z0-9\\s]'\n","    text=re.sub(pattern,'',text)\n","    return text\n","#Apply function on review column\n","imdb_data['review']=imdb_data['review'].apply(remove_special_characters)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"3b66eeabd5b7b8c251f8b8ddf331140a64bcd514","id":"2UyP4comn-hw"},"source":["**Text stemming**"]},{"cell_type":"code","metadata":{"_uuid":"2295f2946e0ab74c220ad538d0e7adc04d23f697","execution":{"iopub.status.busy":"2021-07-08T05:37:39.452117Z","iopub.status.idle":"2021-07-08T05:37:39.452660Z"},"trusted":true,"id":"97kLwJHun-hw"},"source":["#Stemming the text\n","def simple_stemmer(text):\n","    ps=nltk.porter.PorterStemmer()\n","    text= ' '.join([ps.stem(word) for word in text.split()])\n","    return text\n","#Apply function on review column\n","imdb_data['review']=imdb_data['review'].apply(simple_stemmer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"e83107e4a281d84d7ae42b4e2c8d81b7ece438e4","id":"_dBP10k5n-hx"},"source":["**Removing stopwords**"]},{"cell_type":"code","metadata":{"_uuid":"5dbff82b4d2d188d8777b273a75d8ac714d38885","execution":{"iopub.status.busy":"2021-07-08T05:37:39.453859Z","iopub.status.idle":"2021-07-08T05:37:39.454329Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"bJTrfKSln-hx","outputId":"c36df296-00a6-4b22-a97e-8511b83230b7"},"source":["#set stopwords to english\n","stop=set(stopwords.words('english'))\n","print(stop)\n","\n","#removing the stopwords\n","def remove_stopwords(text, is_lower_case=False):\n","    tokens = tokenizer.tokenize(text)\n","    tokens = [token.strip() for token in tokens]\n","    if is_lower_case:\n","        filtered_tokens = [token for token in tokens if token not in stopword_list]\n","    else:\n","        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n","    filtered_text = ' '.join(filtered_tokens)    \n","    return filtered_text\n","#Apply function on review column\n","imdb_data['review']=imdb_data['review'].apply(remove_stopwords)\n","print(imdb_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'ma', \"you'd\", 'such', \"mightn't\", 'ourselves', \"you're\", 'ours', 'on', 'which', 'those', 'me', \"wouldn't\", \"didn't\", 'hers', 'don', \"weren't\", 'should', 'does', 'as', 'shouldn', 'most', 'here', 'i', 'had', \"you'll\", 'this', 'y', \"hadn't\", \"hasn't\", \"won't\", \"haven't\", 'yourselves', 'she', 'each', 'down', 'into', \"aren't\", 'my', 'm', 'him', 'is', 'just', 'needn', 'other', 'we', 'his', 'why', \"wasn't\", \"should've\", 'won', 'by', 'there', 'himself', 'all', 'their', 'again', 'before', 'll', 'its', 'nor', 'your', 'further', 'they', 'being', 'more', 'whom', 'for', 'how', 'no', 'same', 'having', 'to', 'off', 're', 'he', 'o', 'do', 'below', 'until', 'her', 'herself', 'once', 'from', 'when', 'isn', 'out', 'was', 'haven', 'd', 'it', 'above', 've', 'or', 'did', 'own', 'because', 'the', 'doesn', \"doesn't\", 'theirs', 'shan', 'against', 'itself', \"mustn't\", 'doing', 't', 'has', \"isn't\", \"that'll\", \"you've\", 'if', 'between', 'aren', 'up', 'couldn', 'are', 'themselves', 'mustn', \"needn't\", 'were', 'so', 'after', 'hasn', 'ain', 'with', 'during', 'these', 'not', 'been', 'weren', 'where', 'both', 'have', 'under', 'while', 'am', 'can', 'you', 'a', 'who', 'them', \"shouldn't\", 'wouldn', 'at', 'our', 'few', 'be', 'an', 'and', 'yours', 'yourself', \"don't\", 'very', 'than', 'now', 'any', 'myself', 'that', 'mightn', \"she's\", 'some', \"couldn't\", 'too', 'didn', 'wasn', 'hadn', 'in', 'over', 'will', 'what', 'of', 'about', 's', \"it's\", \"shan't\", 'only', 'but', 'through', 'then'}\n","                                                  review sentiment\n","0      one review ha mention watch 1 Oz episod youll ...  positive\n","1      wonder littl product film techniqu veri unassu...  positive\n","2      thought thi wa wonder way spend time hot summe...  positive\n","3      basic famili littl boy jake think zombi hi clo...  negative\n","4      petter mattei love time money visual stun film...  positive\n","...                                                  ...       ...\n","49995  thought thi movi right good job wasnt creativ ...  positive\n","49996  bad plot bad dialogu bad act idiot direct anno...  negative\n","49997  cathol taught parochi elementari school nun ta...  negative\n","49998  Im go disagre previou comment side maltin thi ...  negative\n","49999  one expect star trek movi high art fan expect ...  negative\n","\n","[50000 rows x 2 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"b35e7499291173119ed42287deac6f0cd96516e1","id":"j8rTntErn-hy"},"source":["**Normalized train reviews**"]},{"cell_type":"code","metadata":{"_uuid":"b20c242bd091929ca896ea2c6e936ca00efe6ecf","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-08T05:37:39.456186Z","iopub.status.idle":"2021-07-08T05:37:39.456789Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"dsfu5I5Gn-hy","outputId":"d557a194-2178-4896-c212-61958ae29110"},"source":["#normalized train reviews\n","norm_train_reviews=imdb_data.review[:40000]\n","norm_train_reviews[0]\n","#convert dataframe to string\n","#norm_train_string=norm_train_reviews.to_string()\n","#Spelling correction using Textblob\n","#norm_train_spelling=TextBlob(norm_train_string)\n","#norm_train_spelling.correct()\n","#Tokenization using Textblob\n","#norm_train_words=norm_train_spelling.words\n","#norm_train_words"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'one review ha mention watch 1 Oz episod youll hook right thi exactli happen meth first thing struck Oz wa brutal unflinch scene violenc set right word GO trust thi show faint heart timid thi show pull punch regard drug sex violenc hardcor classic use wordit call OZ nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda Em citi home manyaryan muslim gangsta latino christian italian irish moreso scuffl death stare dodgi deal shadi agreement never far awayi would say main appeal show due fact goe show wouldnt dare forget pretti pictur paint mainstream audienc forget charm forget romanceoz doesnt mess around first episod ever saw struck nasti wa surreal couldnt say wa readi watch develop tast Oz got accustom high level graphic violenc violenc injustic crook guard wholl sold nickel inmat wholl kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch Oz may becom comfort uncomfort viewingthat get touch darker side'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"_uuid":"d69462bb209a66cff86376dc8481d0c0140d894d","id":"Ei1Mv-v9n-hz"},"source":["**Normalized test reviews**"]},{"cell_type":"code","metadata":{"_uuid":"c5d0d38bd9976150367e9d75f3b933774c96a1ab","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-08T05:37:39.458278Z","iopub.status.idle":"2021-07-08T05:37:39.459073Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":177},"id":"2P1KlZN9n-hz","outputId":"313dad25-e624-4812-fa37-873369220c54"},"source":["#Normalized test reviews\n","norm_test_reviews=imdb_data.review[40000:]\n","norm_test_reviews[45005]\n","##convert dataframe to string\n","#norm_test_string=norm_test_reviews.to_string()\n","#spelling correction using Textblob\n","#norm_test_spelling=TextBlob(norm_test_string)\n","#print(norm_test_spelling.correct())\n","#Tokenization using Textblob\n","#norm_test_words=norm_test_spelling.words\n","#norm_test_words"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'read review watch thi piec cinemat garbag took least 2 page find somebodi els didnt think thi appallingli unfunni montag wasnt acm humour 70 inde ani era thi isnt least funni set sketch comedi ive ever seen itll till come along half skit alreadi done infinit better act monti python woodi allen wa say nice piec anim last 90 second highlight thi film would still get close sum mindless drivelridden thi wast 75 minut semin comedi onli world semin realli doe mean semen scatolog humour onli world scat actual fece precursor joke onli mean thi handbook comedi tit bum odd beaver niceif pubesc boy least one hand free havent found playboy exist give break becaus wa earli 70 way sketch comedi go back least ten year prior onli way could even forgiv thi film even made wa gunpoint retro hardli sketch clown subtli pervert children may cut edg circl could actual funni come realli quit sad kept go throughout entir 75 minut sheer belief may save genuin funni skit end gave film 1 becaus wa lower scoreand onli recommend insomniac coma patientsor perhap peopl suffer lockjawtheir jaw would final drop open disbelief'"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"_uuid":"1c2a872ffcb6b8076fdbbba641af12081b6022ef","id":"ABmZQ6T2n-h0"},"source":["###Bags of words model\n","\n","It is used to convert text documents to numerical vectors or bag of words."]},{"cell_type":"code","metadata":{"_uuid":"35cf9dcefb40b2dc520c5b0d559695324c46cc04","execution":{"iopub.status.busy":"2021-07-08T05:37:39.460453Z","iopub.status.idle":"2021-07-08T05:37:39.461186Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"MH9P22Hvn-h0","outputId":"f219e8dd-bd23-4148-e178-c3686139caa2"},"source":["#Count vectorizer for bag of words\n","cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n","#transformed train reviews\n","cv_train_reviews=cv.fit_transform(norm_train_reviews)\n","#transformed test reviews\n","cv_test_reviews=cv.transform(norm_test_reviews)\n","\n","print('BOW_cv_train:',cv_train_reviews.shape)\n","print('BOW_cv_test:',cv_test_reviews.shape)\n","vocab=cv.get_feature_names()\n","\n","print(cv_train_reviews)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BOW_cv_train: (40000, 6209089)\n","BOW_cv_test: (10000, 6209089)\n","  (0, 6092459)\t1\n","  (0, 3322890)\t1\n","  (0, 4543777)\t1\n","  (0, 5804256)\t1\n","  (0, 3921798)\t1\n","  (0, 2427989)\t1\n","  (0, 3419944)\t1\n","  (0, 5161863)\t1\n","  (0, 727813)\t1\n","  (0, 5684597)\t1\n","  (0, 5811823)\t1\n","  (0, 4846998)\t1\n","  (0, 2469715)\t1\n","  (0, 5508678)\t1\n","  (0, 5811052)\t1\n","  (0, 2438285)\t1\n","  (0, 5736630)\t1\n","  (0, 6092460)\t1\n","  (0, 768377)\t1\n","  (0, 2238084)\t1\n","  (0, 3896748)\t1\n","  (0, 4698887)\t1\n","  (0, 5082807)\t1\n","  (0, 3990552)\t1\n","  (0, 3266570)\t1\n","  :\t:\n","  (39999, 4572381)\t1\n","  (39999, 5878931)\t1\n","  (39999, 5279013)\t1\n","  (39999, 2787019)\t1\n","  (39999, 890300)\t1\n","  (39999, 4846045)\t1\n","  (39999, 1428499)\t1\n","  (39999, 3521664)\t1\n","  (39999, 2699914)\t1\n","  (39999, 4641898)\t1\n","  (39999, 3811885)\t1\n","  (39999, 1144944)\t1\n","  (39999, 4159669)\t1\n","  (39999, 753728)\t1\n","  (39999, 4646087)\t1\n","  (39999, 5415954)\t1\n","  (39999, 5950312)\t1\n","  (39999, 1413855)\t1\n","  (39999, 5848653)\t1\n","  (39999, 1856926)\t1\n","  (39999, 504750)\t1\n","  (39999, 4046429)\t1\n","  (39999, 3849837)\t1\n","  (39999, 3209372)\t1\n","  (39999, 407607)\t1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"52371868f05ff9cf157280c5acf0f5bc71ee176d","id":"MdrYW0Gsn-h1"},"source":["**Term Frequency-Inverse Document Frequency model (TFIDF)**\n","\n","It is used to convert text documents to  matrix of  tfidf features."]},{"cell_type":"code","metadata":{"_uuid":"afe6de957339921e05a6faeaf731f2272fd31946","execution":{"iopub.status.busy":"2021-07-08T05:37:39.462494Z","iopub.status.idle":"2021-07-08T05:37:39.463029Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"p5zG7APun-h1","outputId":"1ba6e61d-5173-400b-d75c-9d0e76a37c58"},"source":["#Tfidf vectorizer\n","tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n","#transformed train reviews\n","tv_train_reviews=tv.fit_transform(norm_train_reviews)\n","#transformed test reviews\n","tv_test_reviews=tv.transform(norm_test_reviews)\n","print('Tfidf_train:',tv_train_reviews.shape)\n","print('Tfidf_test:',tv_test_reviews.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tfidf_train: (40000, 6209089)\n","Tfidf_test: (10000, 6209089)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"803e92b25faa738b10928a91de72d177d8dddf85","id":"QbJehiYWn-h2"},"source":["**Labeling the sentiment text**"]},{"cell_type":"code","metadata":{"_uuid":"60f5d496ce4109d1cdbf08f4284d4d26efd93922","execution":{"iopub.status.busy":"2021-07-08T05:37:39.464388Z","iopub.status.idle":"2021-07-08T05:37:39.464836Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"o1J_AryEn-h2","outputId":"40534053-0d5d-453e-f4d8-020dcc4ddf62"},"source":["#labeling the sentient data\n","lb=LabelBinarizer()\n","#transformed sentiment data\n","sentiment_data=lb.fit_transform(imdb_data['sentiment'])\n","print(sentiment_data.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(50000, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"21a80c94fb42e14391c627710c5d796c40aa7dde","id":"PZ-njiZon-h2"},"source":["**Split the sentiment tdata**"]},{"cell_type":"code","metadata":{"_uuid":"ca1e4cc917265ac98a72c37cffe57f27e9897408","_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-07-08T05:37:39.466261Z","iopub.status.idle":"2021-07-08T05:37:39.466679Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"T2YDBcFtn-h3","outputId":"a1b5e8c6-9fad-49e0-d550-5584f867903c"},"source":["#Spliting the sentiment data\n","train_sentiments=sentiment_data[:40000]\n","test_sentiments=sentiment_data[40000:]\n","print(train_sentiments)\n","print(test_sentiments)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1]\n"," [1]\n"," [1]\n"," ...\n"," [1]\n"," [0]\n"," [0]]\n","[[0]\n"," [0]\n"," [0]\n"," ...\n"," [0]\n"," [0]\n"," [0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WDkFjX5Rn-h3"},"source":["#Modelling the dataset"]},{"cell_type":"markdown","metadata":{"_uuid":"d5e45fdc9d062a5b9b9dd665ffe732776e196953","id":"zm7YqVi0n-h3"},"source":["###LSTM Model (Doesn't work, Shows ur RAM has run out)"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.468524Z","iopub.status.idle":"2021-07-08T05:37:39.469093Z"},"trusted":true,"id":"9Lmm_NVTn-h4"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from nltk.corpus import stopwords \n","from collections import Counter\n","import string\n","import re\n","import seaborn as sns\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.470961Z","iopub.status.idle":"2021-07-08T05:37:39.471548Z"},"trusted":true,"id":"YCfs6qQWn-h4"},"source":["class SentimentRNN(nn.Module):\n","    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n","        super(SentimentRNN,self).__init__()\n"," \n","        self.output_dim = output_dim\n","        self.hidden_dim = hidden_dim\n"," \n","        self.no_layers = no_layers\n","        self.vocab_size = vocab_size\n","    \n","        # embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        #lstm\n","        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n","                           num_layers=no_layers, batch_first=True)\n","        \n","        \n","        # dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","    \n","        # linear and sigmoid layer\n","        self.fc = nn.Linear(self.hidden_dim, output_dim)\n","        self.sig = nn.Sigmoid()\n","        \n","    def forward(self,x,hidden):\n","        batch_size = x.size(0)\n","        # embeddings and lstm_out\n","        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n","        #print(embeds.shape)  #[50, 500, 1000]\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","        \n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n","        \n","        # dropout and fully connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        \n","        # sigmoid function\n","        sig_out = self.sig(out)\n","        \n","        # reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        # return last sigmoid output and hidden state\n","        return sig_out, hidden\n","        \n","        \n","        \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim))\n","        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim))\n","        hidden = (h0,c0)\n","        return hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.472789Z","iopub.status.idle":"2021-07-08T05:37:39.473220Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"kAH_K0KUn-h5","outputId":"9650c3bc-499a-4fb9-c9e2-d3762b6b6f8b"},"source":["no_layers = 2\n","vocab_size = len(vocab) + 1 #extra 1 for padding\n","embedding_dim = 64\n","output_dim = 1\n","hidden_dim = 256\n","\n","model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n","\n","print(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SentimentRNN(\n","  (embedding): Embedding(6209090, 64)\n","  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.474380Z","iopub.status.idle":"2021-07-08T05:37:39.474942Z"},"trusted":true,"id":"sD9j6DxHn-h5"},"source":["# loss and optimization functions\n","lr=0.001\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","def acc(pred,label):\n","    pred = torch.round(pred.squeeze())\n","    return torch.sum(pred == label.squeeze()).item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.476648Z","iopub.status.idle":"2021-07-08T05:37:39.477122Z"},"trusted":true,"id":"RkCzR69jn-h6"},"source":["# from torch.utils.data import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.478270Z","iopub.status.idle":"2021-07-08T05:37:39.478881Z"},"trusted":true,"id":"Q8-Vk4a5n-h6"},"source":["# class SentencesDataset(Dataset):\n","#     def __init__(self, data):\n","#         self.data = data\n","        \n","#     def __len__(self):\n","#         return len(self.data)\n","    \n","#     # get items    \n","#     def __getitem__(self, idx):\n","#         return {'sentence':self.data[idx][1], 'label':self.data[idx][2]}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.480316Z","iopub.status.idle":"2021-07-08T05:37:39.480783Z"},"trusted":true,"id":"0722oI5yn-h7"},"source":["cv_train_reviews.toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.482760Z","iopub.status.idle":"2021-07-08T05:37:39.483267Z"},"trusted":true,"id":"pBYxrXldn-h7"},"source":["train_data = TensorDataset(torch.from_numpy(cv_train_reviews), torch.from_numpy(train_sentiments))\n","test_data = TensorDataset(torch.from_numpy(cv_test_reviews), torch.from_numpy(test_sentiments))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.484881Z","iopub.status.idle":"2021-07-08T05:37:39.485319Z"},"trusted":true,"id":"0v3u_M0Pn-h8"},"source":["# train_dataset = SentencesDataset(cv_train_reviews)\n","# test_dataset = SentencesDataset(cv_test_reviews)\n","train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=50, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=50, shuffle=False)\n","batch_size = 50"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.486774Z","iopub.status.idle":"2021-07-08T05:37:39.487264Z"},"trusted":true,"id":"ct3YEWksn-h8"},"source":["dataiter = iter(train_loader)\n","sample_x, sample_y = dataiter.next()\n","\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print('Sample input: \\n', sample_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-08T05:37:39.489209Z","iopub.status.idle":"2021-07-08T05:37:39.489701Z"},"trusted":true,"id":"PDT97YvUn-h8"},"source":["clip = 5\n","epochs = 5 \n","valid_loss_min = np.Inf\n","# train for some number of epochs\n","epoch_tr_loss,epoch_vl_loss = [],[]\n","epoch_tr_acc,epoch_vl_acc = [],[]\n","\n","for epoch in range(epochs):\n","    train_losses = []\n","    train_acc = 0.0\n","    model.train()\n","    # initialize hidden state \n","    h = model.init_hidden(batch_size)\n","    for inputs, labels in train_loader:\n","        \n","        # inputs, labels = inputs.to(device), labels.to(device)    \n","        # Creating new variables for the hidden state, otherwise\n","        # we'd backprop through the entire training history\n","        h = tuple([each.data for each in h])\n","        \n","        model.zero_grad()\n","        output,h = model(inputs,h)\n","        \n","        # calculate the loss and perform backprop\n","        loss = criterion(output.squeeze(), labels.float())\n","        loss.backward()\n","        train_losses.append(loss.item())\n","        # calculating accuracy\n","        accuracy = acc(output,labels)\n","        train_acc += accuracy\n","        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","        nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n"," \n","    \n","        \n","    val_h = model.init_hidden(batch_size)\n","    val_losses = []\n","    val_acc = 0.0\n","    model.eval()\n","    for inputs, labels in test_loader:\n","            val_h = tuple([each.data for each in val_h])\n","\n","            inputs, labels = inputs, labels\n","\n","            output, val_h = model(inputs, val_h)\n","            val_loss = criterion(output.squeeze(), labels.float())\n","\n","            val_losses.append(val_loss.item())\n","            \n","            accuracy = acc(output,labels)\n","            val_acc += accuracy\n","            \n","    epoch_train_loss = np.mean(train_losses)\n","    epoch_val_loss = np.mean(val_losses)\n","    epoch_train_acc = train_acc/len(train_loader.dataset)\n","    epoch_val_acc = val_acc/len(test_loader.dataset)\n","    epoch_tr_loss.append(epoch_train_loss)\n","    epoch_vl_loss.append(epoch_val_loss)\n","    epoch_tr_acc.append(epoch_train_acc)\n","    epoch_vl_acc.append(epoch_val_acc)\n","    print(f'Epoch {epoch+1}') \n","    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n","    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n","    if epoch_val_loss <= valid_loss_min:\n","        torch.save(model.state_dict(), '../working/state_dict.pt')\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n","        valid_loss_min = epoch_val_loss\n","    print(25*'==')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7D_pufyo2Gzi"},"source":["#LIME"]},{"cell_type":"code","metadata":{"id":"Om8H1AfTn-h9"},"source":["! pip install lime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAti4HVu1yaw"},"source":["from lime import lime_text\n","from sklearn.pipeline import make_pipeline\n","\n","c = make_pipeline(cv, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZX1DdOZz1y4f"},"source":["from lime.lime_text import LimeTextExplainer\n","\n","explainer = LimeTextExplainer(class_names=[0,1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"grLkNBLM1zOJ"},"source":["idx =64\n","exp = explainer.explain_instance(norm_train_reviews[idx], c.predict_proba, num_features=8)\n","print('True class: %s' % test_sentiments[idx])\n","exp.show_in_notebook(text=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hHXZ_AqN1zlj"},"source":["!pip install lime\n","from lime import lime_text\n","from sklearn.pipeline import make_pipeline\n","\n","c = make_pipeline(cv, model)\n","from lime.lime_text import LimeTextExplainer\n","\n","explainer = LimeTextExplainer(class_names=[0,1])\n","\n","idx =64\n","exp = explainer.explain_instance(norm_train_reviews[idx], c.predict_proba, num_features=8)\n","print('True class: %s' % test_sentiments[idx])\n","exp.show_in_notebook(text=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CB_qRHJ_105x"},"source":["lig = LayerIntegratedGradients(model, model.embedding)\n"],"execution_count":null,"outputs":[]}]}